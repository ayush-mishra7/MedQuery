# MedQuery â€“ Medical Report Q&A & Summarization Engine

MedQuery is a lightweight AI-powered tool that uses LLMs to analyze medical reports and generate:
- **Questionâ€“Answer responses** based on the report
- **Short summaries**
- **Detailed clinical summaries**
- **Doctor-style structured summaries**

The backend is built using **FastAPI** and powered by **Groqâ€™s LLaMA 3.1** model.

---

## ğŸš€ Features

### ğŸ”¹ Medical Q&A  
Ask any question about a medical report (diagnosis, findings, test results, etc.).

### ğŸ”¹ Multi-Level Summarization  
Automatically generate:
1. Short summary  
2. Detailed summary  
3. Doctor-style structured summary  

### ğŸ”¹ Minimal & Lightweight  
No heavy ML libraries â€” logic handled through LLM prompts.

---

## ğŸ“ Project Structure

medquery/
â”‚â”€â”€ requirements.txt
â”‚â”€â”€ Dockerfile
â”‚â”€â”€ README.md
â”‚â”€â”€ app/
â”‚ â”œâ”€â”€ main.py
â”‚ â”œâ”€â”€ utils.py
â”‚ â”œâ”€â”€ models.py


---

## ğŸ”§ Installation

### 1. Create Conda environment
conda create -n medquery python=3.10 -y
conda activate medquery


### 2. Install dependencies
pip install -r requirements.txt


### 3. Add your Groq API Key  
Create a `.env` file (optional) or paste directly in `main.py`:

YOUR_API_KEY_HERE


---

## â–¶ï¸ Run the API

Use Uvicorn:
uvicorn app.main:app --reload


Open the Swagger docs:

ğŸ‘‰ http://127.0.0.1:8000/docs

---

## ğŸ³ Run with Docker

### Build image:
docker build -t medquery .


### Run container:
docker run -p 8000:8000 medquery


---

## ğŸ“Œ Endpoints

### **POST /qa**
Input:
```json
{
  "report": "Patient shows...",
  "question": "What is the diagnosis?"
}

POST /summarize

Input:
{
  "report": "Patient shows..."
}


~ Ayush Mishra